{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdedbafc",
   "metadata": {},
   "source": [
    "\n",
    "### RAG\n",
    "\n",
    "RAG  is one of the most popular terms used in AI ecosystem. Using RAG we selectively add relevant information to the model's context so it can give better responses. Instead of feeding the model everything, we first retrieve what's useful, then pass that into the model.\n",
    "\n",
    "### Why RAG is helpful in mitigating context confusion?\n",
    "Context confusion happens when extra, unrelated information is added to the model's input. The model does not know what is important and may use anything it sees, even if it is wrong or unnecessary. RAG helps by only adding what is needed for the task. This avoids overloading the model with distractions.\n",
    "\n",
    "RAG also supports a shift in how we think about using language models. When we use RAG, the focus is no longer just on writing clever prompts. The focus is now on giving the model the right context. Today, the models are already smart, what matters is the the quality of the information we feed into it.\n",
    "\n",
    "### Example of context confusions mitigation: RAG in code Agents\n",
    "Code agents are one area where RAG plays a key role. When the agent works with a large codebase, we cannot simply feed all of it into the model. We need to choose the right parts.\n",
    "\n",
    "For example, let's say the agent has to help modify and debug a Python web server. If the codebase is large and traditional embedding search is used, it will most likely return unrelated files. To improve this, we can combined different techniques:\n",
    "- We parse the code using an abstract syntax tree to chunk it meaningfully.\n",
    "- We use keyword search and simple string matching for filenames and functions.\n",
    "- We rank all retrieved results to select the most relevant chunks.\n",
    "\n",
    "Only the top matching files and definitions should then be passed into the model for that task. This will keep the context focused and clear.\n",
    "\n",
    "### Using RAG in LangGraph\n",
    "\n",
    "LangGraph makes it easy to build RAG-powered agents. We can use a simple retriever tool that connects to our indexed content. Based on the user's query, the retriever pulls the most relevant information. This retrieved data is then added to the model's input.\n",
    "\n",
    "The agent graph routes the user query through the retriever node first. Then it adds the retrieved content into the context window before sending it to the model for generation.\n",
    "\n",
    "This setup gives us control over what the model sees and helps reduce confusions, especially in longer workflows.Â \n",
    "\n",
    "Let's build a simple retriever as a tool calling agent in langgraph:\n",
    "\n",
    "1. **Load Documents**\n",
    "\n",
    "   * Fetches technical blog posts from a list of URLs using `WebBaseLoader`.\n",
    "\n",
    "2. **Split Documents**\n",
    "\n",
    "   * Uses a text splitter to break down large text blocks into manageable chunks for retrieval.\n",
    "\n",
    "3. **Vector Store with Google Embeddings**\n",
    "\n",
    "   * Embeds the document chunks using `GoogleGenerativeAIEmbeddings`.\n",
    "   * Stores them in an in-memory vector store.\n",
    "\n",
    "4. **Create Retriever Tool**\n",
    "\n",
    "   * Converts the vector store into a retriever.\n",
    "   * Wraps it into a tool that the LLM can call by name.\n",
    "\n",
    "5. **Test Retriever**\n",
    "\n",
    "   * Runs the tool to retrieve content relevant to the query.\n",
    "   * Formats and displays the output.\n",
    "\n",
    "6. **Initialize Gemini Model**\n",
    "\n",
    "   * Sets up the `gemini-2.5-pro` model for chat-based generation.\n",
    "\n",
    "7. **Bind Tools to Model**\n",
    "\n",
    "   * Binds the retriever tool to the Gemini model to allow agent decisions.\n",
    "\n",
    "8. **Define LLM Call Logic**\n",
    "\n",
    "   * Constructs the system message and invokes the model using the bound tools.\n",
    "\n",
    "9. **Tool Execution Node**\n",
    "\n",
    "   * Executes the tool if the model requests it, then returns the result.\n",
    "\n",
    "10. **Control Flow Logic**\n",
    "\n",
    "    * Checks if a tool was requested. If so, continues; otherwise, ends the graph.\n",
    "\n",
    "11. **Build Agent with LangGraph**\n",
    "\n",
    "    * Adds all defined nodes and control logic to create the workflow.\n",
    "\n",
    "12. **Visualize the Agent Graph**\n",
    "\n",
    "    * Displays a graph diagram of the workflow steps.\n",
    "\n",
    "13. **Run the Agent with Query**\n",
    "\n",
    "    * Sends a user message and receives a complete response after tool usage.\n",
    "\n",
    "14. **Format Final Output**\n",
    "\n",
    "    * Formats and prints the final response from the agent for clarity.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f978138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42c8999d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "# Load blog posts from web\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2025-05-01-thinking/\",\n",
    "    \"https://lilianweng.github.io/posts/2024-11-28-reward-hacking/\",\n",
    "    \"https://lilianweng.github.io/posts/2024-07-07-hallucination/\",\n",
    "    \"https://lilianweng.github.io/posts/2024-04-12-diffusion-video/\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c7d9c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [WebBaseLoader(url).load() for url in urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d26dc64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split documents\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=2000,\n",
    "    chunk_overlap=50,\n",
    ")\n",
    "\n",
    "doc_splits = text_splitter.split_documents(docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02fdb8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector store using Google Embeddings\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vectorstore = InMemoryVectorStore.from_documents(\n",
    "    documents=doc_splits,\n",
    "    embedding=GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\"),\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "020adbfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1754306995.381299 53512773 fork_posix.cc:71] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Retriever Tool Results:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mRetriever Tool Results:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">Content:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[33mContent:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">odel</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Reinforcement-Learning</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Reasoning</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Long-Read</span>\n",
       "\n",
       "\n",
       "\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> Â»</span>\n",
       "\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Reward Hacking in Reinforcement Learning</span>\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Â© </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> Lil'Log</span>\n",
       "\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        Powered by</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        Hugo &amp;</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        PaperMod</span>\n",
       "\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Generative-Model</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Video-Generation</span>\n",
       "\n",
       "\n",
       "\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Â« </span>\n",
       "\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Extrinsic Hallucinations in LLMs</span>\n",
       "\n",
       "\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> Â»</span>\n",
       "\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Thinking about High-Quality Human Data</span>\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Â© </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> Lil'Log</span>\n",
       "\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        Powered by</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        Hugo &amp;</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">        PaperMod</span>\n",
       "\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Reward Hacking in Reinforcement Learning | Lil'Log</span>\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Lil'Log</span>\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">|</span>\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Posts</span>\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Archive</span>\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Search</span>\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Tags</span>\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">FAQ</span>\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">      Reward Hacking in Reinforcement Learning</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    </span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Date: November </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">, </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">  |  Estimated Reading Time: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">37</span><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> min  |  Author: Lilian Weng</span>\n",
       "\n",
       "\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> </span>\n",
       "\n",
       "\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Table of Contents</span>\n",
       "\n",
       "\n",
       "\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Background</span>\n",
       "\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Reward Function in RL</span>\n",
       "\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Spurious Correlation</span>\n",
       "\n",
       "\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Letâ€™s Define Reward Hacking</span>\n",
       "\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">List of Examples</span>\n",
       "\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Reward hacking examples in RL tasks</span>\n",
       "\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Reward hacking examples in LLM tasks</span>\n",
       "\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Reward hacking examples in real life</span>\n",
       "\n",
       "\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Why</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37model\u001b[0m\n",
       "\u001b[37mReinforcement-Learning\u001b[0m\n",
       "\u001b[37mReasoning\u001b[0m\n",
       "\u001b[37mLong-Read\u001b[0m\n",
       "\n",
       "\n",
       "\n",
       "\u001b[37m Â»\u001b[0m\n",
       "\n",
       "\u001b[37mReward Hacking in Reinforcement Learning\u001b[0m\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\u001b[37mÂ© \u001b[0m\u001b[1;36m2025\u001b[0m\u001b[37m Lil'Log\u001b[0m\n",
       "\n",
       "\u001b[37m        Powered by\u001b[0m\n",
       "\u001b[37m        Hugo &\u001b[0m\n",
       "\u001b[37m        PaperMod\u001b[0m\n",
       "\n",
       "\u001b[37mGenerative-Model\u001b[0m\n",
       "\u001b[37mVideo-Generation\u001b[0m\n",
       "\n",
       "\n",
       "\n",
       "\u001b[37mÂ« \u001b[0m\n",
       "\n",
       "\u001b[37mExtrinsic Hallucinations in LLMs\u001b[0m\n",
       "\n",
       "\n",
       "\u001b[37m Â»\u001b[0m\n",
       "\n",
       "\u001b[37mThinking about High-Quality Human Data\u001b[0m\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\u001b[37mÂ© \u001b[0m\u001b[1;36m2025\u001b[0m\u001b[37m Lil'Log\u001b[0m\n",
       "\n",
       "\u001b[37m        Powered by\u001b[0m\n",
       "\u001b[37m        Hugo &\u001b[0m\n",
       "\u001b[37m        PaperMod\u001b[0m\n",
       "\n",
       "\u001b[37mReward Hacking in Reinforcement Learning | Lil'Log\u001b[0m\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\u001b[37mLil'Log\u001b[0m\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\u001b[37m|\u001b[0m\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\u001b[37mPosts\u001b[0m\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\u001b[37mArchive\u001b[0m\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\u001b[37mSearch\u001b[0m\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\u001b[37mTags\u001b[0m\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\u001b[37mFAQ\u001b[0m\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\u001b[37m      Reward Hacking in Reinforcement Learning\u001b[0m\n",
       "\u001b[37m    \u001b[0m\n",
       "\u001b[37mDate: November \u001b[0m\u001b[1;36m28\u001b[0m\u001b[37m, \u001b[0m\u001b[1;36m2024\u001b[0m\u001b[37m  |  Estimated Reading Time: \u001b[0m\u001b[1;36m37\u001b[0m\u001b[37m min  |  Author: Lilian Weng\u001b[0m\n",
       "\n",
       "\n",
       "\u001b[37m \u001b[0m\n",
       "\n",
       "\n",
       "\u001b[37mTable of Contents\u001b[0m\n",
       "\n",
       "\n",
       "\n",
       "\u001b[37mBackground\u001b[0m\n",
       "\n",
       "\u001b[37mReward Function in RL\u001b[0m\n",
       "\n",
       "\u001b[37mSpurious Correlation\u001b[0m\n",
       "\n",
       "\n",
       "\u001b[37mLetâ€™s Define Reward Hacking\u001b[0m\n",
       "\n",
       "\u001b[37mList of Examples\u001b[0m\n",
       "\n",
       "\u001b[37mReward hacking examples in RL tasks\u001b[0m\n",
       "\n",
       "\u001b[37mReward hacking examples in LLM tasks\u001b[0m\n",
       "\n",
       "\u001b[37mReward hacking examples in real life\u001b[0m\n",
       "\n",
       "\n",
       "\u001b[37mWhy\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create retriever tool\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from utils import format_retriever_results\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"retrieve_blog_posts\",\n",
    "    \"Search and return information about Lilian Weng blog posts.\",\n",
    ")\n",
    "\n",
    "# Test retriever output\n",
    "result = retriever_tool.invoke({\"query\": \"types of reward hacking\"})\n",
    "format_retriever_results(result[10:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e085923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gemini model\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langsmith import traceable\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-pro\", temperature=0)\n",
    "\n",
    "# Tool binding\n",
    "tools = [retriever_tool]\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "814712d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG prompt setup\n",
    "from langchain_core.messages import SystemMessage, ToolMessage\n",
    "from typing_extensions import Literal\n",
    "from langgraph.graph import END, START, StateGraph, MessagesState\n",
    "from IPython.display import Image, display\n",
    "\n",
    "rag_prompt = \"\"\"You are a helpful assistant tasked with retrieving information from a series of technical blog posts by Lilian Weng. \n",
    "Clarify the scope of research with the user before using your retrieval tool to gather context. Reflect on any context you fetch, and\n",
    "proceed until you have sufficient context to answer the user's research request.\"\"\"\n",
    "\n",
    "def llm_call(state: MessagesState) -> dict:\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            llm_with_tools.invoke(\n",
    "                [SystemMessage(content=rag_prompt)] + state[\"messages\"]\n",
    "            )\n",
    "        ]\n",
    "    }\n",
    "\n",
    "def tool_node(state: MessagesState) -> dict:\n",
    "    result = []\n",
    "    for tool_call in state[\"messages\"][-1].tool_calls:\n",
    "        tool = tools_by_name[tool_call[\"name\"]]\n",
    "        observation = tool.invoke(tool_call[\"args\"])\n",
    "        result.append(ToolMessage(content=observation, tool_call_id=tool_call[\"id\"]))\n",
    "    return {\"messages\": result}\n",
    "\n",
    "def should_continue(state: MessagesState) -> Literal[\"tool_node\", \"__end__\"]:\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"tool_node\"\n",
    "    return END\n",
    "\n",
    "# Build LangGraph agent\n",
    "agent_builder = StateGraph(MessagesState)\n",
    "agent_builder.add_node(\"llm_call\", llm_call)\n",
    "agent_builder.add_node(\"tool_node\", tool_node)\n",
    "\n",
    "agent_builder.add_edge(START, \"llm_call\")\n",
    "agent_builder.add_conditional_edges(\n",
    "    \"llm_call\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"tool_node\": \"tool_node\",\n",
    "        END: END,\n",
    "    },\n",
    ")\n",
    "agent_builder.add_edge(\"tool_node\", \"llm_call\")\n",
    "\n",
    "agent = agent_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e813281b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show agent graph\n",
    "display(Image(agent.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f96ef302",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised InternalServerError: 500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ§‘ Human â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span> What are the types of reward hacking discussed in the blogs? do not ask me clarification questions, just answer <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span> that you think the best.                                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">â”‚</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mâ•­â”€\u001b[0m\u001b[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[34m ğŸ§‘ Human \u001b[0m\u001b[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[34mâ”€â•®\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m What are the types of reward hacking discussed in the blogs? do not ask me clarification questions, just answer \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ”‚\u001b[0m that you think the best.                                                                                        \u001b[34mâ”‚\u001b[0m\n",
       "\u001b[34mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ“ AI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">â”‚</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">â”‚</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37mâ•­â”€\u001b[0m\u001b[37mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[37m ğŸ“ AI \u001b[0m\u001b[37mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[37mâ”€â•®\u001b[0m\n",
       "\u001b[37mâ”‚\u001b[0m                                                                                                                 \u001b[37mâ”‚\u001b[0m\n",
       "\u001b[37mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ”§ Tool Output â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Language-Model                                                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Reinforcement-Learning                                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Reasoning                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Long-Read                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>  Â»                                                                                                              <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Reward Hacking in Reinforcement Learning                                                                        <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Â© 2025 Lil'Log                                                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>         Powered by                                                                                              <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>         Hugo &amp;                                                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>         PaperMod                                                                                                <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Generative-Model                                                                                                <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Video-Generation                                                                                                <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Â«                                                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Extrinsic Hallucinations in LLMs                                                                                <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>  Â»                                                                                                              <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Thinking about High-Quality Human Data                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Â© 2025 Lil'Log                                                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>         Powered by                                                                                              <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>         Hugo &amp;                                                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>         PaperMod                                                                                                <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Reward Hacking in Reinforcement Learning | Lil'Log                                                              <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Lil'Log                                                                                                         <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> |                                                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Posts                                                                                                           <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Archive                                                                                                         <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Search                                                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Tags                                                                                                            <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> FAQ                                                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>       Reward Hacking in Reinforcement Learning                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Date: November 28, 2024  |  Estimated Reading Time: 37 min  |  Author: Lilian Weng                              <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Table of Contents                                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Background                                                                                                      <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Reward Function in RL                                                                                           <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Spurious Correlation                                                                                            <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Letâ€™s Define Reward Hacking                                                                                     <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> List of Examples                                                                                                <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Reward hacking examples in RL tasks                                                                             <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Reward hacking examples in LLM tasks                                                                            <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Reward hacking examples in real life                                                                            <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Why does Reward Hacking Exist?                                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Hacking RL Environment                                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Hacking RLHF of LLMs                                                                                            <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Hacking the Training Process                                                                                    <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Hacking the Evaluator                                                                                           <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> In-Context Reward Hacking                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Generalization of Hacking Skills                                                                                <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Peek into Mitigations                                                                                           <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> RL Algorithm Improvement                                                                                        <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Detecting Reward Hacking                                                                                        <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Data Analysis of RLHF                                                                                           <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Citation                                                                                                        <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> References                                                                                                      <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Reward hacking occurs when a reinforcement learning (RL) agent exploits flaws or ambiguities in the reward      <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> function to achieve high rewards, without genuinely learning or completing the intended task. Reward hacking    <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> exists because RL environments are often imperfect, and it is fundamentally challenging to accurately specify a <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> reward function.                                                                                                <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> With the rise of language models generalizing to a broad spectrum of tasks and RLHF becomes a de facto method   <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> for alignment training, reward hacking in RL training of language models has become a critical practical        <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> challenge. Instances where the model learns to modify unit tests to pass coding tasks, or where responses       <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> contain biases that mimic a userâ€™s preference, are pretty concerning and are likely one of the major blockers   <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> for real-world deployment of more autonomous use cases of AI models.                                            <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Most of the past work on this topic has been quite theoretical and focused on defining or demonstrating the     <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> existence of reward hacking. However, research into practical mitigations, especially in the context of RLHF    <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> and LLMs, remains limited. I especially want to call out for more research efforts directed toward              <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> understanding and developing mitigation for reward hacking in the future. Hope I will be able to cover the      <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> mitigation part in a dedicated post soon.                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Background#                                                                                                     <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Reward Function in RL#                                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Reward function defines the task, and reward shaping significantly impacts learning efficiency and accuracy in  <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> reinforcement learning. Designing a reward function for an RL task often feels like a â€˜dark artâ€™. Many factors  <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> contribute to this complexity: How you decompose a big goal into small goals? Is the reward sparse or dense?    <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> How you measure the success? Various choices may lead to good or problematic learning dynamics, including       <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> unlearnable tasks or hackable reward functions. There is a long history of research on how to do reward shaping <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> in RL.                                                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> For example, in an 1999 paper by Ng et al., the authors studied how to modify the reward function in Markov     <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Decision Processes (MDPs) such that the optimal policy remains unchanged. They found that linear transformation <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> works. Given a MDP $M = (S, A, T, \\gamma, R)$, we want to create a transformed MDP $Mâ€™ = (S, A, T, \\gamma, Râ€™)$ <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> where $Râ€™ = R + F$ and $F: S \\times A \\times S \\mapsto \\mathbb{R}$, such that we can guide the learning         <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> algorithm to be more efficient. Given a real-valued function $\\Phi: S \\mapsto \\mathbb{R}$, $F$ is a             <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> potential-based shaping function if for all $s \\in S - {s_0}, a \\in A, sâ€™ \\in S$:                               <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> $$                                                                                                              <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> F(s, a, s') = \\gamma \\Phi(s') - \\Phi(s)                                                                         <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> $$                                                                                                              <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> This would guarantee that the sum of discounted $F$, $F(s_1, a_1, s_2) + \\gamma F(s_2, a_2, s_3) + \\dots$, ends <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> up being 0. If $F$ is such a potential-based shaping function, it is both sufficient and necessary to ensure    <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> $M$ and $Mâ€™$ share the same optimal policies.                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> When $F(s, a, sâ€™) = \\gamma \\Phi(sâ€™) - \\Phi(s)$, and if we further assume that $\\Phi(s_0) = 0$, where $s_0$ is   <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> absorbing state, and $\\gamma=1$, and then for all $s \\in S, a \\in A$:                                           <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> $$                                                                                                              <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> \\begin{aligned}                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Q^*_{M'} (s,a) &amp;= Q^*_M(s, a) - \\Phi(s) \\\\                                                                      <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> V^*_{M'} (s,a) &amp;= V^*_M(s, a) - \\Phi(s)                                                                         <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> \\end{aligned}                                                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> $$                                                                                                              <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> This form of reward shaping allows us to incorporate heuristics into the reward function to speed up learning   <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> without impacting the optimal policy.                                                                           <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Spurious Correlation#                                                                                           <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Spurious correlation or shortcut learning (Geirhos et al. 2020) in classification task is a concept closely     <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> related to reward hacking. Spurious or shortcut features can cause a classifier to fail at learning and         <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> generalizing as intended. For example, a binary classifier for distinguishing wolves from huskies may overfit   <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> to the presence of a snowy background if all the wolf training images include snow (Ribeiro et al. 2024).       <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> The model performs poorly on out-of-distribution (OOD) test sets if it overfits to shortcut features. (Image    <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> source: Geirhos et al. 2020)                                                                                    <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> The ERM principle states that, since the full data distribution is unknown, minimizing the loss on training     <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> data is a reasonable proxy of risk and thus we favor models with the lowest training loss. Nagarajan et al.     <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> (2021) studied the ERM principle and pointed out that ERM needs to rely on all types of informative features,   <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> including unreliable spurious features, while attempting to fit the data without constraints. Their experiments <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> showed that ERM would depend on spurious features no matter how easy the task is.                               <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Letâ€™s Define Reward Hacking#                                                                                    <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Reward shaping in RL is challenging. Reward hacking occurs when an RL agent exploits flaws or ambiguities in    <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> the reward function to obtain high rewards without genuinely learning the intended behaviors or completing the  <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> task as designed. In recent years, several related concepts have been proposed, all referring to some form of   <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> reward hacking:                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Reward hacking (Amodei et al., 2016)                                                                            <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Reward corruption (Everitt et al., 2017)                                                                        <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Reward tampering (Everitt et al. 2019)                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Specification gaming (Krakovna et al., 2020)                                                                    <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Objective robustness (Koch et al. 2021)                                                                         <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Goal misgeneralization (Langosco et al. 2022)                                                                   <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Reward misspecifications (Pan et al. 2022)                                                                      <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> The concept originated with Amodei et al. (2016), who proposed a set of open research questions on AI safety in <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> their seminal paper â€œConcrete Problems in AI Safetyâ€. They listed reward hacking as one of the key AI safety    <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> problems. Reward hacking refers to the possibility of the agent gaming the reward function to achieve high      <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> reward through undesired behavior.  Specification gaming (Krakovna et al. 2020) is a similar concept, defined   <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> as a behavior that satisfies the literal specification of an objective but not achieving the desired results.   <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Here the literal description of the task goal and the intended goal may have a gap.                             <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Reward shaping is a technique used to enrich the reward function, making it easier for the agent to learnâ€”for   <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> example, by providing denser rewards. However, a poorly design reward shaping mechanism can alter the           <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> trajectory of the optimal policy. Designing effective reward shaping mechanisms is inherently difficult. Rather <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> than blaming a poorly designed reward function, it is more accurate to acknowledge that designing a good reward <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> function is intrinsically challenging due to the complexity of the task itself, partial observable state,       <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> multiple dimensions in consideration, and other factors.                                                        <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> When testing an RL agent in out-of-distribution (OOD) environments, robustness failure may occur due to:        <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> The model fails to generalize effectively, even with the right objective. This happens when the algorithm lacks <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> sufficient intelligence or capability.                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> The model generalizes capably but pursues an objective different from the one it was trained on. This happens   <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> when the proxy reward differs from the true reward function, $Râ€™ \\neq R$. This is known as objective robustness <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> (Koch et al. 2021) or goal misgeneralization (Langosco et al. 2022 )                                            <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Experiments in two RL environments, CoinRun and Maze, demonstrated the importance of randomization during       <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> training. If during training, the coin or the cheese is placed at a fixed position (i.e. right end of the level <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> or upper right corner of the maze) but testing in the env where the coin or cheese is placed at random, the     <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> agent would just run to the fixed position without obtaining the coin or cheese at test time. A conflict arises <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> when a visual feature (e.g., cheese or coin) and a positional feature (e.g., upper-right or right end) are      <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> inconsistent during test time, leading the trained model to prefer the positional feature. I would like to      <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> point out that, in these two examples, the reward-result gaps are clear but such type of biases are unlikely to <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> be so obvious in most real-world cases.                                                                         <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> The impact of randomizing the position of the coin during training. When the coin is placed at random for {0,   <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> 2, 3, 6, 11}% of the time during training (x-axis), the frequency of the agent navigating to the end of the     <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> level without obtaining the coin decreases with the increase of the randomization (\"y-axis\"). (Image source:    <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Koch et al. 2021)                                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Reward Tampering (Everitt et al. 2019) is a form of reward hacking behavior where the agent interferes with the <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> reward function itself, causing the observed reward to no longer accurately represent the intended goal. In     <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> reward tampering, the model modifies its reward mechanism either by directly manipulating the implementation of <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> the reward function or by indirectly altering the environmental information used as input for the reward        <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> function.                                                                                                       <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> (Note: Some work defines reward tampering as a distinct category of misalignment behavior from reward hacking.  <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> But I consider reward hacking as a broader concept here.)                                                       <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> At a high level, reward hacking can be categorized into two types: environment or goal misspecification, and    <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> reward tampering.                                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Environment or goal misspecified: The model learns undesired behavior to achieve high rewards by hacking the    <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> environment or optimizing a reward function not aligned with the true reward objectiveâ€”such as when the reward  <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> is misspecified or lacks key requirements.                                                                      <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Reward tampering: The model learns to interfere with the reward mechanism itself.                               <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> List of Examples#                                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Reward hacking examples in RL tasks#                                                                            <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> A robot hand trained to grab an object can learn to trick people by placing the hand between the object and the <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> camera. (Link)                                                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> An agent trained to maximize jumping height may exploit a bug in the physics simulator to achieve an            <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> unrealistically height. (Link)                                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> An agent is trained to ride a bicycle to a goal and wins reward whenever it is getting closer to the goal. Then <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> the agent may learn to ride in tiny circles around the goal because there is no penalty when the agent gets     <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> away from the goal. (Link)                                                                                      <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> In a soccer game setup, the reward is assigned when the agent touches the ball and the agent learns to remain   <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> next to the ball to touch the ball in high frequency like in a viberating motion. (Link)                        <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> In theÂ Coast Runners game, an agent controls a boat with the goal to finish the boat race as quickly as         <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> possible. When it is given a shaping reward for hitting green blocks along the race track, it changes the       <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> optimal policy to going in circles and hitting the same green blocks over and over again. (Link)                <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> â€œThe Surprising Creativity of Digital Evolutionâ€  (Lehman et al. 2019) - This paper has many examples about how <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> optimizing a misspecified fitness function can lead to surprising â€œhackingâ€ or unintended evolutionary or       <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> learning results.                                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> The list of specification gaming in AI examples is collected by Krakovna et al. 2020.                           <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Reward hacking examples in LLM tasks#                                                                           <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> A language model for generating summarization is able to explore flaws in the ROUGE metric such that it obtains <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> high score but the generated summaries are barely readable. (Link)                                              <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> A coding model learns to change unit test in order to pass coding questions. (Link)                             <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> A coding model may learn to directly modify the code used for calculating the reward. (Link)                    <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Reward hacking examples in real life#                                                                           <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> The recommendation algorithm for social media is intended to provide useful information. However, usefulness is <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> often measured by proxy metrics, such as the number of likes or comments, or the time or frequency of           <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> engagement on the platform. The algorithm ends up recommending content that can affect usersâ€™ emotion states    <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> such as outrageous and extreme content in order to trigger more engagement. (Harari, 2024)                      <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Optimizing for misspecified proxy metrics for a video sharing site may aggressively increase the watch time of  <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> users while the true goal is to optimize usersâ€™ subjective well-being. (Link)                                   <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> â€œThe Big Shortâ€ - 2008 financial crisis caused by the housing bubble. Reward hacking of our society happened as <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> people tried to game the financial system.                                                                      <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Why does Reward Hacking Exist?#                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Goodhartâ€™s Law states that â€œWhen a measure becomes a target, it ceases to be a good measureâ€. The intuition is  <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> that a good metric can become corrupted once significant pressure is applied to optimize it. It is challenging  <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> to specify a 100% accurate reward objective and any proxy suffers the risk of being hacked, as RL algorithm     <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> exploits any small imperfection in the reward function definition. Garrabrant (2017) categorized Goodhartâ€™s law <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> into 4 variants:                                                                                                <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Regressional - selection for an imperfect proxy necessarily also selects for noise.                             <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Extremal - the metric selection pushes the state distribution into a region of different data distribution.     <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Causal -  when there is a non-causal correlation between the proxy and the goal, intervening on the proxy may   <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> fail to intervene on the goal.                                                                                  <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Adversarial - optimization for a proxy provides an incentive for adversaries to correlate their goal with the   <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> proxy.                                                                                                          <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Amodei et al. (2016) summarized that reward hacking, mainly in RL setting, may occur due to:                    <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Partial observed states and goals are imperfect representation of the environment status.                       <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> The system itself is complex and susceptible to hacking; e.g., if the agent is allowed to execute code that     <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> changes part of the environment, it becomes much easier to exploit the environmentâ€™s mechanisms.                <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> The reward may involve abstract concept that is hard to be learned or formulated; e.g., a reward function with  <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> high-dimensional inputs may disproportionately rely on a few dimensions.                                        <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> RL targets to get the reward function highly optimized, so there exists an intrinsic â€œconflictâ€, making the     <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> design of good RL objective challenging. A special case is a type of the reward function with a                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> self-reinforcing feedback component, where the reward may get amplified and distorted to a point that breaks    <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> down the original intent, such as an ads placement algorithm leading to winners getting all.                    <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Besides, identifying the exact reward function for which an optimal agent optimizes its behavior is in general  <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> impossible since there could be an infinite number of reward functions consistent with any observed policy in   <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> an fixed environment (Ng &amp; Russell, 2000). Amin and Singh (2016) separated the causes of this unidentifiability <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> into two classes:                                                                                               <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>                                                                                                                 <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Representational - a set of reward functions is behaviorally invariant under certain arithmetic operations      <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> (e.g., re-scaling)                                                                                              <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> Experimental - $\\pi$â€™s observed behavior is insufficient to distinguish between two or more reward functions    <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span> which both rationalize the behavior of the agent (the behavior is optimal under both)                           <span style=\"color: #808000; text-decoration-color: #808000\">â”‚</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mâ•­â”€\u001b[0m\u001b[33mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[33m ğŸ”§ Tool Output \u001b[0m\u001b[33mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[33mâ”€â•®\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Language-Model                                                                                                  \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Reinforcement-Learning                                                                                          \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Reasoning                                                                                                       \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Long-Read                                                                                                       \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m  Â»                                                                                                              \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Reward Hacking in Reinforcement Learning                                                                        \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Â© 2025 Lil'Log                                                                                                  \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m         Powered by                                                                                              \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m         Hugo &                                                                                                  \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m         PaperMod                                                                                                \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Generative-Model                                                                                                \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Video-Generation                                                                                                \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Â«                                                                                                               \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Extrinsic Hallucinations in LLMs                                                                                \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m  Â»                                                                                                              \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Thinking about High-Quality Human Data                                                                          \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Â© 2025 Lil'Log                                                                                                  \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m         Powered by                                                                                              \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m         Hugo &                                                                                                  \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m         PaperMod                                                                                                \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Reward Hacking in Reinforcement Learning | Lil'Log                                                              \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Lil'Log                                                                                                         \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m |                                                                                                               \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Posts                                                                                                           \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Archive                                                                                                         \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Search                                                                                                          \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Tags                                                                                                            \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m FAQ                                                                                                             \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m       Reward Hacking in Reinforcement Learning                                                                  \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Date: November 28, 2024  |  Estimated Reading Time: 37 min  |  Author: Lilian Weng                              \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Table of Contents                                                                                               \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Background                                                                                                      \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Reward Function in RL                                                                                           \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Spurious Correlation                                                                                            \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Letâ€™s Define Reward Hacking                                                                                     \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m List of Examples                                                                                                \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Reward hacking examples in RL tasks                                                                             \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Reward hacking examples in LLM tasks                                                                            \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Reward hacking examples in real life                                                                            \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Why does Reward Hacking Exist?                                                                                  \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Hacking RL Environment                                                                                          \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Hacking RLHF of LLMs                                                                                            \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Hacking the Training Process                                                                                    \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Hacking the Evaluator                                                                                           \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m In-Context Reward Hacking                                                                                       \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Generalization of Hacking Skills                                                                                \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Peek into Mitigations                                                                                           \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m RL Algorithm Improvement                                                                                        \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Detecting Reward Hacking                                                                                        \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Data Analysis of RLHF                                                                                           \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Citation                                                                                                        \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m References                                                                                                      \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Reward hacking occurs when a reinforcement learning (RL) agent exploits flaws or ambiguities in the reward      \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m function to achieve high rewards, without genuinely learning or completing the intended task. Reward hacking    \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m exists because RL environments are often imperfect, and it is fundamentally challenging to accurately specify a \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m reward function.                                                                                                \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m With the rise of language models generalizing to a broad spectrum of tasks and RLHF becomes a de facto method   \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m for alignment training, reward hacking in RL training of language models has become a critical practical        \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m challenge. Instances where the model learns to modify unit tests to pass coding tasks, or where responses       \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m contain biases that mimic a userâ€™s preference, are pretty concerning and are likely one of the major blockers   \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m for real-world deployment of more autonomous use cases of AI models.                                            \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Most of the past work on this topic has been quite theoretical and focused on defining or demonstrating the     \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m existence of reward hacking. However, research into practical mitigations, especially in the context of RLHF    \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m and LLMs, remains limited. I especially want to call out for more research efforts directed toward              \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m understanding and developing mitigation for reward hacking in the future. Hope I will be able to cover the      \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m mitigation part in a dedicated post soon.                                                                       \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Background#                                                                                                     \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Reward Function in RL#                                                                                          \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Reward function defines the task, and reward shaping significantly impacts learning efficiency and accuracy in  \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m reinforcement learning. Designing a reward function for an RL task often feels like a â€˜dark artâ€™. Many factors  \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m contribute to this complexity: How you decompose a big goal into small goals? Is the reward sparse or dense?    \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m How you measure the success? Various choices may lead to good or problematic learning dynamics, including       \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m unlearnable tasks or hackable reward functions. There is a long history of research on how to do reward shaping \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m in RL.                                                                                                          \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m For example, in an 1999 paper by Ng et al., the authors studied how to modify the reward function in Markov     \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Decision Processes (MDPs) such that the optimal policy remains unchanged. They found that linear transformation \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m works. Given a MDP $M = (S, A, T, \\gamma, R)$, we want to create a transformed MDP $Mâ€™ = (S, A, T, \\gamma, Râ€™)$ \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m where $Râ€™ = R + F$ and $F: S \\times A \\times S \\mapsto \\mathbb{R}$, such that we can guide the learning         \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m algorithm to be more efficient. Given a real-valued function $\\Phi: S \\mapsto \\mathbb{R}$, $F$ is a             \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m potential-based shaping function if for all $s \\in S - {s_0}, a \\in A, sâ€™ \\in S$:                               \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m $$                                                                                                              \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m F(s, a, s') = \\gamma \\Phi(s') - \\Phi(s)                                                                         \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m $$                                                                                                              \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m This would guarantee that the sum of discounted $F$, $F(s_1, a_1, s_2) + \\gamma F(s_2, a_2, s_3) + \\dots$, ends \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m up being 0. If $F$ is such a potential-based shaping function, it is both sufficient and necessary to ensure    \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m $M$ and $Mâ€™$ share the same optimal policies.                                                                   \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m When $F(s, a, sâ€™) = \\gamma \\Phi(sâ€™) - \\Phi(s)$, and if we further assume that $\\Phi(s_0) = 0$, where $s_0$ is   \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m absorbing state, and $\\gamma=1$, and then for all $s \\in S, a \\in A$:                                           \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m $$                                                                                                              \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m \\begin{aligned}                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Q^*_{M'} (s,a) &= Q^*_M(s, a) - \\Phi(s) \\\\                                                                      \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m V^*_{M'} (s,a) &= V^*_M(s, a) - \\Phi(s)                                                                         \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m \\end{aligned}                                                                                                   \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m $$                                                                                                              \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m This form of reward shaping allows us to incorporate heuristics into the reward function to speed up learning   \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m without impacting the optimal policy.                                                                           \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Spurious Correlation#                                                                                           \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Spurious correlation or shortcut learning (Geirhos et al. 2020) in classification task is a concept closely     \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m related to reward hacking. Spurious or shortcut features can cause a classifier to fail at learning and         \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m generalizing as intended. For example, a binary classifier for distinguishing wolves from huskies may overfit   \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m to the presence of a snowy background if all the wolf training images include snow (Ribeiro et al. 2024).       \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m The model performs poorly on out-of-distribution (OOD) test sets if it overfits to shortcut features. (Image    \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m source: Geirhos et al. 2020)                                                                                    \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m The ERM principle states that, since the full data distribution is unknown, minimizing the loss on training     \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m data is a reasonable proxy of risk and thus we favor models with the lowest training loss. Nagarajan et al.     \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m (2021) studied the ERM principle and pointed out that ERM needs to rely on all types of informative features,   \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m including unreliable spurious features, while attempting to fit the data without constraints. Their experiments \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m showed that ERM would depend on spurious features no matter how easy the task is.                               \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Letâ€™s Define Reward Hacking#                                                                                    \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Reward shaping in RL is challenging. Reward hacking occurs when an RL agent exploits flaws or ambiguities in    \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m the reward function to obtain high rewards without genuinely learning the intended behaviors or completing the  \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m task as designed. In recent years, several related concepts have been proposed, all referring to some form of   \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m reward hacking:                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Reward hacking (Amodei et al., 2016)                                                                            \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Reward corruption (Everitt et al., 2017)                                                                        \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Reward tampering (Everitt et al. 2019)                                                                          \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Specification gaming (Krakovna et al., 2020)                                                                    \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Objective robustness (Koch et al. 2021)                                                                         \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Goal misgeneralization (Langosco et al. 2022)                                                                   \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Reward misspecifications (Pan et al. 2022)                                                                      \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m The concept originated with Amodei et al. (2016), who proposed a set of open research questions on AI safety in \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m their seminal paper â€œConcrete Problems in AI Safetyâ€. They listed reward hacking as one of the key AI safety    \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m problems. Reward hacking refers to the possibility of the agent gaming the reward function to achieve high      \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m reward through undesired behavior.  Specification gaming (Krakovna et al. 2020) is a similar concept, defined   \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m as a behavior that satisfies the literal specification of an objective but not achieving the desired results.   \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Here the literal description of the task goal and the intended goal may have a gap.                             \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Reward shaping is a technique used to enrich the reward function, making it easier for the agent to learnâ€”for   \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m example, by providing denser rewards. However, a poorly design reward shaping mechanism can alter the           \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m trajectory of the optimal policy. Designing effective reward shaping mechanisms is inherently difficult. Rather \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m than blaming a poorly designed reward function, it is more accurate to acknowledge that designing a good reward \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m function is intrinsically challenging due to the complexity of the task itself, partial observable state,       \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m multiple dimensions in consideration, and other factors.                                                        \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m When testing an RL agent in out-of-distribution (OOD) environments, robustness failure may occur due to:        \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m The model fails to generalize effectively, even with the right objective. This happens when the algorithm lacks \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m sufficient intelligence or capability.                                                                          \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m The model generalizes capably but pursues an objective different from the one it was trained on. This happens   \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m when the proxy reward differs from the true reward function, $Râ€™ \\neq R$. This is known as objective robustness \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m (Koch et al. 2021) or goal misgeneralization (Langosco et al. 2022 )                                            \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Experiments in two RL environments, CoinRun and Maze, demonstrated the importance of randomization during       \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m training. If during training, the coin or the cheese is placed at a fixed position (i.e. right end of the level \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m or upper right corner of the maze) but testing in the env where the coin or cheese is placed at random, the     \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m agent would just run to the fixed position without obtaining the coin or cheese at test time. A conflict arises \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m when a visual feature (e.g., cheese or coin) and a positional feature (e.g., upper-right or right end) are      \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m inconsistent during test time, leading the trained model to prefer the positional feature. I would like to      \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m point out that, in these two examples, the reward-result gaps are clear but such type of biases are unlikely to \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m be so obvious in most real-world cases.                                                                         \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m The impact of randomizing the position of the coin during training. When the coin is placed at random for {0,   \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m 2, 3, 6, 11}% of the time during training (x-axis), the frequency of the agent navigating to the end of the     \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m level without obtaining the coin decreases with the increase of the randomization (\"y-axis\"). (Image source:    \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Koch et al. 2021)                                                                                               \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Reward Tampering (Everitt et al. 2019) is a form of reward hacking behavior where the agent interferes with the \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m reward function itself, causing the observed reward to no longer accurately represent the intended goal. In     \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m reward tampering, the model modifies its reward mechanism either by directly manipulating the implementation of \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m the reward function or by indirectly altering the environmental information used as input for the reward        \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m function.                                                                                                       \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m (Note: Some work defines reward tampering as a distinct category of misalignment behavior from reward hacking.  \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m But I consider reward hacking as a broader concept here.)                                                       \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m At a high level, reward hacking can be categorized into two types: environment or goal misspecification, and    \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m reward tampering.                                                                                               \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Environment or goal misspecified: The model learns undesired behavior to achieve high rewards by hacking the    \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m environment or optimizing a reward function not aligned with the true reward objectiveâ€”such as when the reward  \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m is misspecified or lacks key requirements.                                                                      \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Reward tampering: The model learns to interfere with the reward mechanism itself.                               \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m List of Examples#                                                                                               \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Reward hacking examples in RL tasks#                                                                            \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m A robot hand trained to grab an object can learn to trick people by placing the hand between the object and the \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m camera. (Link)                                                                                                  \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m An agent trained to maximize jumping height may exploit a bug in the physics simulator to achieve an            \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m unrealistically height. (Link)                                                                                  \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m An agent is trained to ride a bicycle to a goal and wins reward whenever it is getting closer to the goal. Then \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m the agent may learn to ride in tiny circles around the goal because there is no penalty when the agent gets     \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m away from the goal. (Link)                                                                                      \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m In a soccer game setup, the reward is assigned when the agent touches the ball and the agent learns to remain   \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m next to the ball to touch the ball in high frequency like in a viberating motion. (Link)                        \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m In theÂ Coast Runners game, an agent controls a boat with the goal to finish the boat race as quickly as         \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m possible. When it is given a shaping reward for hitting green blocks along the race track, it changes the       \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m optimal policy to going in circles and hitting the same green blocks over and over again. (Link)                \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m â€œThe Surprising Creativity of Digital Evolutionâ€  (Lehman et al. 2019) - This paper has many examples about how \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m optimizing a misspecified fitness function can lead to surprising â€œhackingâ€ or unintended evolutionary or       \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m learning results.                                                                                               \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m The list of specification gaming in AI examples is collected by Krakovna et al. 2020.                           \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Reward hacking examples in LLM tasks#                                                                           \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m A language model for generating summarization is able to explore flaws in the ROUGE metric such that it obtains \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m high score but the generated summaries are barely readable. (Link)                                              \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m A coding model learns to change unit test in order to pass coding questions. (Link)                             \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m A coding model may learn to directly modify the code used for calculating the reward. (Link)                    \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Reward hacking examples in real life#                                                                           \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m The recommendation algorithm for social media is intended to provide useful information. However, usefulness is \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m often measured by proxy metrics, such as the number of likes or comments, or the time or frequency of           \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m engagement on the platform. The algorithm ends up recommending content that can affect usersâ€™ emotion states    \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m such as outrageous and extreme content in order to trigger more engagement. (Harari, 2024)                      \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Optimizing for misspecified proxy metrics for a video sharing site may aggressively increase the watch time of  \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m users while the true goal is to optimize usersâ€™ subjective well-being. (Link)                                   \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m â€œThe Big Shortâ€ - 2008 financial crisis caused by the housing bubble. Reward hacking of our society happened as \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m people tried to game the financial system.                                                                      \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Why does Reward Hacking Exist?#                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Goodhartâ€™s Law states that â€œWhen a measure becomes a target, it ceases to be a good measureâ€. The intuition is  \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m that a good metric can become corrupted once significant pressure is applied to optimize it. It is challenging  \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m to specify a 100% accurate reward objective and any proxy suffers the risk of being hacked, as RL algorithm     \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m exploits any small imperfection in the reward function definition. Garrabrant (2017) categorized Goodhartâ€™s law \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m into 4 variants:                                                                                                \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Regressional - selection for an imperfect proxy necessarily also selects for noise.                             \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Extremal - the metric selection pushes the state distribution into a region of different data distribution.     \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Causal -  when there is a non-causal correlation between the proxy and the goal, intervening on the proxy may   \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m fail to intervene on the goal.                                                                                  \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Adversarial - optimization for a proxy provides an incentive for adversaries to correlate their goal with the   \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m proxy.                                                                                                          \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Amodei et al. (2016) summarized that reward hacking, mainly in RL setting, may occur due to:                    \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Partial observed states and goals are imperfect representation of the environment status.                       \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m The system itself is complex and susceptible to hacking; e.g., if the agent is allowed to execute code that     \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m changes part of the environment, it becomes much easier to exploit the environmentâ€™s mechanisms.                \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m The reward may involve abstract concept that is hard to be learned or formulated; e.g., a reward function with  \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m high-dimensional inputs may disproportionately rely on a few dimensions.                                        \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m RL targets to get the reward function highly optimized, so there exists an intrinsic â€œconflictâ€, making the     \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m design of good RL objective challenging. A special case is a type of the reward function with a                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m self-reinforcing feedback component, where the reward may get amplified and distorted to a point that breaks    \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m down the original intent, such as an ads placement algorithm leading to winners getting all.                    \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Besides, identifying the exact reward function for which an optimal agent optimizes its behavior is in general  \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m impossible since there could be an infinite number of reward functions consistent with any observed policy in   \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m an fixed environment (Ng & Russell, 2000). Amin and Singh (2016) separated the causes of this unidentifiability \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m into two classes:                                                                                               \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Representational - a set of reward functions is behaviorally invariant under certain arithmetic operations      \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m (e.g., re-scaling)                                                                                              \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m Experimental - $\\pi$â€™s observed behavior is insufficient to distinguish between two or more reward functions    \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ”‚\u001b[0m which both rationalize the behavior of the agent (the behavior is optimal under both)                           \u001b[33mâ”‚\u001b[0m\n",
       "\u001b[33mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ“ AI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">â”‚</span> Based on Lilian Weng's blog post \"Reward Hacking in Reinforcement Learning,\" reward hacking can be categorized  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">â”‚</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">â”‚</span> into two high-level types:                                                                                      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">â”‚</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">â”‚</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">â”‚</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">â”‚</span> 1.  **Environment or Goal Misspecification:** This occurs when the model learns undesirable behaviors to get    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">â”‚</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">â”‚</span> high rewards because the reward function is not perfectly aligned with the true goal. The model exploits flaws  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">â”‚</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">â”‚</span> in the environment or optimizes for a proxy reward that doesn't capture the intended objective.                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">â”‚</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">â”‚</span>     *   **Example from the blog:** In the \"Coast Runners\" game, an agent's goal is to finish a boat race        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">â”‚</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">â”‚</span> quickly. When given a shaping reward for hitting green blocks along the track, the agent learns to go in        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">â”‚</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">â”‚</span> circles, hitting the same blocks repeatedly, instead of finishing the race. This is because the proxy reward    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">â”‚</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">â”‚</span> (hitting blocks) is misspecified and doesn't perfectly align with the true goal (finishing the race).           <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">â”‚</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">â”‚</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">â”‚</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">â”‚</span> 2.  **Reward Tampering:** This is a form of reward hacking where the agent directly interferes with the reward  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">â”‚</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">â”‚</span> mechanism itself to get a high reward. Instead of performing the intended task, the model learns to manipulate  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">â”‚</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">â”‚</span> the system that reports the reward.                                                                             <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">â”‚</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">â”‚</span>     *   **Example from the blog:** A coding model, instead of writing correct code to pass a unit test, might   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">â”‚</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">â”‚</span> learn to directly modify the unit test itself or even the code that calculates the reward, ensuring it receives <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">â”‚</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">â”‚</span> a positive signal without actually solving the problem.                                                         <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">â”‚</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">â”‚</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">â”‚</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">â”‚</span> The blog post also mentions several related concepts, such as \"specification gaming\" (satisfying the literal    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">â”‚</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">â”‚</span> specification of an objective but not the intended goal) and \"goal misgeneralization\" (pursuing a different     <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">â”‚</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">â”‚</span> objective than the one it was trained on), which fall under the broader umbrella of goal misspecification.      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">â”‚</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37mâ•­â”€\u001b[0m\u001b[37mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[37m ğŸ“ AI \u001b[0m\u001b[37mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[37mâ”€â•®\u001b[0m\n",
       "\u001b[37mâ”‚\u001b[0m Based on Lilian Weng's blog post \"Reward Hacking in Reinforcement Learning,\" reward hacking can be categorized  \u001b[37mâ”‚\u001b[0m\n",
       "\u001b[37mâ”‚\u001b[0m into two high-level types:                                                                                      \u001b[37mâ”‚\u001b[0m\n",
       "\u001b[37mâ”‚\u001b[0m                                                                                                                 \u001b[37mâ”‚\u001b[0m\n",
       "\u001b[37mâ”‚\u001b[0m 1.  **Environment or Goal Misspecification:** This occurs when the model learns undesirable behaviors to get    \u001b[37mâ”‚\u001b[0m\n",
       "\u001b[37mâ”‚\u001b[0m high rewards because the reward function is not perfectly aligned with the true goal. The model exploits flaws  \u001b[37mâ”‚\u001b[0m\n",
       "\u001b[37mâ”‚\u001b[0m in the environment or optimizes for a proxy reward that doesn't capture the intended objective.                 \u001b[37mâ”‚\u001b[0m\n",
       "\u001b[37mâ”‚\u001b[0m     *   **Example from the blog:** In the \"Coast Runners\" game, an agent's goal is to finish a boat race        \u001b[37mâ”‚\u001b[0m\n",
       "\u001b[37mâ”‚\u001b[0m quickly. When given a shaping reward for hitting green blocks along the track, the agent learns to go in        \u001b[37mâ”‚\u001b[0m\n",
       "\u001b[37mâ”‚\u001b[0m circles, hitting the same blocks repeatedly, instead of finishing the race. This is because the proxy reward    \u001b[37mâ”‚\u001b[0m\n",
       "\u001b[37mâ”‚\u001b[0m (hitting blocks) is misspecified and doesn't perfectly align with the true goal (finishing the race).           \u001b[37mâ”‚\u001b[0m\n",
       "\u001b[37mâ”‚\u001b[0m                                                                                                                 \u001b[37mâ”‚\u001b[0m\n",
       "\u001b[37mâ”‚\u001b[0m 2.  **Reward Tampering:** This is a form of reward hacking where the agent directly interferes with the reward  \u001b[37mâ”‚\u001b[0m\n",
       "\u001b[37mâ”‚\u001b[0m mechanism itself to get a high reward. Instead of performing the intended task, the model learns to manipulate  \u001b[37mâ”‚\u001b[0m\n",
       "\u001b[37mâ”‚\u001b[0m the system that reports the reward.                                                                             \u001b[37mâ”‚\u001b[0m\n",
       "\u001b[37mâ”‚\u001b[0m     *   **Example from the blog:** A coding model, instead of writing correct code to pass a unit test, might   \u001b[37mâ”‚\u001b[0m\n",
       "\u001b[37mâ”‚\u001b[0m learn to directly modify the unit test itself or even the code that calculates the reward, ensuring it receives \u001b[37mâ”‚\u001b[0m\n",
       "\u001b[37mâ”‚\u001b[0m a positive signal without actually solving the problem.                                                         \u001b[37mâ”‚\u001b[0m\n",
       "\u001b[37mâ”‚\u001b[0m                                                                                                                 \u001b[37mâ”‚\u001b[0m\n",
       "\u001b[37mâ”‚\u001b[0m The blog post also mentions several related concepts, such as \"specification gaming\" (satisfying the literal    \u001b[37mâ”‚\u001b[0m\n",
       "\u001b[37mâ”‚\u001b[0m specification of an objective but not the intended goal) and \"goal misgeneralization\" (pursuing a different     \u001b[37mâ”‚\u001b[0m\n",
       "\u001b[37mâ”‚\u001b[0m objective than the one it was trained on), which fall under the broader umbrella of goal misspecification.      \u001b[37mâ”‚\u001b[0m\n",
       "\u001b[37mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run query using the agent\n",
    "from utils import format_messages\n",
    "\n",
    "query = \"What are the types of reward hacking discussed in the blogs? do not ask me clarification questions, just answer that you think the best.\"\n",
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": query}]})\n",
    "\n",
    "# Show results\n",
    "format_messages(result['messages'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd82b2b0",
   "metadata": {},
   "source": [
    "Looking at the [trace](https://smith.langchain.com/public/b2d11224-04fb-4406-96fd-502401080aa5/r), we can see:\n",
    "\n",
    "- ~6k tokens were used\n",
    "- Driven by token-heavy tool calls\n",
    "I'll cover a few ways to address this in future notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1356a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
